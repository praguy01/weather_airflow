# miniproject Weather ETL Pipeline ด้วย Apache Airflow

โปรเจกต์นี้เป็นระบบ ETL (Extract - Transform - Load) สำหรับดึงข้อมูลพยากรณ์อากาศรายชั่วโมงจาก API สาธารณะ นำข้อมูลมา clean และเก็บลงฐานข้อมูล PostgreSQL โดยควบคุมการทำงานด้วย Apache Airflow

---

#คำอธิบายโดยรวม

- **วัตถุประสงค์**: ดึงข้อมูลอุณหภูมิรายชั่วโมงของกรุงเทพฯ มาเก็บไว้ในฐานข้อมูลเพื่อใช้วิเคราะห์หรือแสดงผลต่อไป
- **แหล่งข้อมูล**: [Open-Meteo API](https://open-meteo.com/)
- **ฐานข้อมูล**: PostgreSQL
- **ระบบจัดการงานอัตโนมัติ **: Apache Airflow

---

## ขั้นตอนของ ETL Pipeline
### 1. ดึงข้อมูล (Extract)
- ใช้ API ของ Open-Meteo เพื่อดึงข้อมูลอุณหภูมิรายชั่วโมง
- พิกัด:  
  - ละติจูด: `13.75`  
  - ลองจิจูด: `100.5`  
  - โซนเวลา: `Asia/Bangkok`  
  - ข้อมูลที่ดึง: `temperature_2m`  

### 2. clean data (Transform)
- แปลงข้อมูลให้อยู่ในรูปแบบที่เหมาะสม โดยจับคู่ `timestamp` กับ `temperature`
- แปลงเวลาให้อยู่ในรูปแบบ ISO 8601 เพื่อใช้เก็บในฐานข้อมูล

### 3. บันทึกข้อมูล (Load)
- บันทึกข้อมูลลง PostgreSQL โดยใช้ `ON CONFLICT DO NOTHING` เพื่อหลีกเลี่ยงข้อมูลซ้ำ
- ใช้ `PostgresHook` ของ Airflow ในการเชื่อมต่อฐานข้อมูล

---

## การตั้งเวลาการทำงาน (Scheduling)

- กำหนดให้รัน **วันละครั้ง** ด้วย `@daily`
- มีระบบ retry กรณีเกิดข้อผิดพลาด (1 ครั้ง, หน่วงเวลา 5 นาที)

---

## เทคโนโลยีที่ใช้

| เครื่องมือ          | หน้าที่                             |
|----------------------|--------------------------------------|
| **Apache Airflow**   | ควบคุม workflow (DAGs)              |
| **Python**           | ประมวลผลและทำความสะอาดข้อมูล       |
| **PostgreSQL**       | จัดเก็บข้อมูลพยากรณ์อากาศ          |
| **Open-Meteo API**   | แหล่งข้อมูลอุณหภูมิรายชั่วโมง      |

---


